# About the pipeline
# The business context: 
The videos are generated by a pipeline that processes the data in the following way:
1. The user choose the topic. The topics are created outside the application.
2. The user can choose what he would like to input. The input can be a idea, image, video, text.
3. User provides the input, choose template, topic and the pipeline starts.
4. The pipeline processes the input and generates video script. The video script is a json file that contains the information about the video and scenes.
5. The end will validate the video script, can make changes to the script or request changes on the video script, or even deny the video script.
6. if the video script receives any change, the pipeline will start again from step 4, but this time the pipeline will use the video script.
7. The video script is then validated for existence of the required resources such as images, videos, audio, etc.
8. The end user (content creator) can then provide the resources or request the resources from the pipeline. 
9. Once all the resources are provided the piple will generate the video, and uploads in to youtube, and sends the message to the end user.
10. The end user can then add the audio, and publish the video.



# Technical implementation

The list of statuses for the pipeline are as follows: created, processing, completed, failed, denied, pending, validated, invalid, approved, rejected, uploaded, published, deleted.

The pipeline is implemented using the following components:
Apache airflow
Docker
Python


## Task 1 (Nikhita)
data_video.json will be there in a folder. When the program runs, it has to read the data from the json file, if its available. If not available program will not run, if its available, it will process the json file create the video and upload in to youtube.

### Detailed steps
1. Check if the data_video.json is available in the folder. use the dropboxapi.
2. If the file is not available, just exit the program.
3. If the file is available, download the file.
4. Read the file and process the data.
5. After creating and upload the video, move the file to archive folder.
6. Exit the program.

## Task 2 : Upload the data_video.json to dropbox. (Sirisha)
This function will take the parameters topic, input, template. The function will create the data_video.json file and upload the file to dropbox, and send mail to the end user.

Use Open AI to create the data_video.json file contents, by providing the required information such as topic, input, template.
upload the file to dropbox (this is a new function to be created)
send mail to the end user. The end user email is configured in the config file. (The function to send mail will be provided), for the send_email function pass the subject, body and email. Subject: "New file uploaded to dropbox", body: "The file data_video.json is uploaded to dropbox. Please check the file."



